{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My summary\n",
    "\n",
    "## Tensors and Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides two kinds of data abstractions called tensors and variables. Tensors are similar to numpy arrays and they can also be used on GPUs, which provide increased performance. They provide easy methods of switching between GPUs and CPUs. For certain operations, we can notice a boost in performance and machine learning algorithms\n",
    "can understand different forms of data, only when represented as tensors of numbers.\n",
    "Tensors are like Python arrays and can change in size. For example, images can be represented as three-dimensional arrays (height, weight, channel (RGB)). It is common in deep learning to use tensors of sizes up to five dimensions. Some of the commonly used tensors are as follows:\n",
    "- Scalar (0-D tensors)\n",
    "- Vector (1-D tensors)\n",
    "- Matrix (2-D tensors)\n",
    "- 3-D tensors\n",
    "- Slicing tensors\n",
    "- 4-D tensors\n",
    "- 5-D tensors\n",
    "- Tensors on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar (0-D tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor containing only one element is called a scalar. It will generally be of type FloatTensor or LongTensor. At the time of writing, PyTorch does not have a special tensor with zero dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9424, 0.2152, 0.7102, 0.4808, 0.1377, 0.8498, 0.3962, 0.5214, 0.7608,\n",
      "        0.8140])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(10)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors (1-D tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector is simply an array of elements. For example, we can use a vector to store the average temperature for the last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([23, 24, 24.5, 26, 27, 27.2, 23.0])\n",
    "print(temp.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# This is a 1D-tensor\n",
    "a = torch.tensor([2,2,1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix (2-D tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the structured data is represented in the form of tables or matrices. Torch provides a utility function called\n",
    "from_numpy, which converts a numpy array into a torch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 4],\n",
      "        [3, 5, 4],\n",
      "        [1, 2, 0],\n",
      "        [4, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "# This is a 2D-tensor\n",
    "b = torch.tensor([[2,1,4], [3,5,4], [1,2,0], [4,3,2]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# The size of the tensors\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Get the heigth/number of rows of b\n",
    "print(b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4.],\n",
      "        [3., 5., 4.],\n",
      "        [1., 2., 0.],\n",
      "        [4., 3., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# This is a 2D-float-tensor\n",
    "b = torch.FloatTensor([[2,1,4], [3,5,4], [1,2,0], [4,3,2]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 1.])\n"
     ]
    }
   ],
   "source": [
    "# This is a 2D-float-tensor\n",
    "a = torch.tensor([2,2,1], dtype = torch.float)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4.],\n",
      "        [3., 5., 4.],\n",
      "        [1., 2., 0.],\n",
      "        [4., 3., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# This is a 2D-double-tensor\n",
    "b = torch.DoubleTensor([[2,1,4], [3,5,4], [1,2,0], [4,3,2]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# This is a 2D-double-tensor\n",
    "a = torch.tensor([2,2,1], dtype = torch.double)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# print tensor type\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4.],\n",
      "        [3., 5., 4.],\n",
      "        [1., 2., 0.],\n",
      "        [4., 3., 2.]], dtype=torch.float64)\n",
      "tensor([[2.],\n",
      "        [1.],\n",
      "        [4.],\n",
      "        [3.],\n",
      "        [5.],\n",
      "        [4.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [4.],\n",
      "        [3.],\n",
      "        [2.]], dtype=torch.float64)\n",
      "tensor([2., 1., 4., 3., 5., 4., 1., 2., 0., 4., 3., 2.], dtype=torch.float64)\n",
      "tensor([[2., 1., 4., 3.],\n",
      "        [5., 4., 1., 2.],\n",
      "        [0., 4., 3., 2.]], dtype=torch.float64)\n",
      "tensor([[2., 1., 4., 3.],\n",
      "        [5., 4., 1., 2.],\n",
      "        [0., 4., 3., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Rechape b\n",
    "# If one of the dimensions is -1, its size can be inferred\n",
    "# the size -1 is inferred from other dimensions\n",
    "# view: Returns a new tensor with the same data but different size.\n",
    "print(b)\n",
    "print(b.view(-1, 1))   \n",
    "print(b.view(12))\n",
    "print(b.view(-1, 4))\n",
    "print(b.view(3, 4))\n",
    "b = b.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Boston House Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a dataset called Boston House Prices, which is readily available in the Python scikit-learn machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00,  ..., 1.5300e+01, 3.9690e+02,\n",
      "         4.9800e+00],\n",
      "        [2.7310e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9690e+02,\n",
      "         9.1400e+00],\n",
      "        [2.7290e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9283e+02,\n",
      "         4.0300e+00],\n",
      "        ...,\n",
      "        [6.0760e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
      "         5.6400e+00],\n",
      "        [1.0959e-01, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9345e+02,\n",
      "         6.4800e+00],\n",
      "        [4.7410e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
      "         7.8800e+00]], dtype=torch.float64)\n",
      "torch.Size([506, 13])\n",
      "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
      "         6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
      "         4.9800e+00],\n",
      "        [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 6.4210e+00,\n",
      "         7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9690e+02,\n",
      "         9.1400e+00]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "boston_tensor = torch.from_numpy(boston.data)\n",
    "print(boston_tensor)\n",
    "print(boston_tensor.size())\n",
    "print(boston_tensor[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7552, 0.2980, 0.5711, 0.1019],\n",
      "        [0.3721, 0.7840, 0.2033, 0.1114],\n",
      "        [0.3158, 0.3965, 0.4299, 0.0122],\n",
      "        [0.0571, 0.4342, 0.4824, 0.9562]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix with random numbers between 0 and 1\n",
    "r = torch.rand(4, 4)\n",
    "print(r)\n",
    "print(r.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5987,  2.7831, -1.3662, -1.8046],\n",
      "        [ 0.8115, -0.7716,  0.0513, -0.2709],\n",
      "        [-0.8423,  0.8892, -0.3247,  0.2348],\n",
      "        [-0.0828,  0.4432, -1.6563, -1.6077]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix with random numbers taken a normal distribution\n",
    "# with mean 0 and variance 1\n",
    "r2 = torch.randn(4, 4)\n",
    "print(r2)\n",
    "print(r2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 9, 8, 8, 9])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create an array of 5 random integers from values between 6 and 9\n",
    "# (exclusive of 10)\n",
    "in_array = torch.randint(6, 10, (5,))\n",
    "print(in_array)\n",
    "print(in_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 6, 9],\n",
      "        [7, 7, 8],\n",
      "        [9, 6, 6]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D-array (matrix) of size 3x3 filled with random integers\n",
    "# from values between 6 and 9 (exclusive of 10)\n",
    "in_array2 = torch.randint(6, 10, (3,3))\n",
    "print(in_array2)\n",
    "print(in_array2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Get a number of elements in in_array\n",
    "print(torch.numel(in_array))\n",
    "# Get a number of elements in in_array2\n",
    "print(torch.numel(in_array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "torch.int64\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Construct a 3x3 matrix of zeros and of dtype long\n",
    "z = torch.zeros(3, 3, dtype=torch.long)\n",
    "print(z)\n",
    "print(z.dtype)\n",
    "# Construct a 3x3 matrix of ones and of dtype long\n",
    "z = torch.ones(3, 3)\n",
    "print(z)\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2528,  0.1718, -1.2319,  1.0089],\n",
      "        [-1.1698,  1.1939,  0.7745,  0.2273],\n",
      "        [ 0.5267,  0.8730,  1.0343,  0.8326],\n",
      "        [-0.9843,  0.7574,  1.3067,  0.3439]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Convert the data type of the tensor\n",
    "r2_like = torch.randn_like(r2, dtype=torch.double)\n",
    "print(r2_like)\n",
    "print(r2_like.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1565,  3.0811, -0.7951, -1.7028],\n",
      "        [ 1.1836,  0.0123,  0.2547, -0.1595],\n",
      "        [-0.5265,  1.2856,  0.1052,  0.2470],\n",
      "        [-0.0257,  0.8773, -1.1739, -0.6515]])\n"
     ]
    }
   ],
   "source": [
    "# Add two tensor\n",
    "add_result = torch.add(r, r2)\n",
    "print(add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5987,  2.7831, -1.3662, -1.8046],\n",
      "        [ 0.8115, -0.7716,  0.0513, -0.2709],\n",
      "        [-0.8423,  0.8892, -0.3247,  0.2348],\n",
      "        [-0.0828,  0.4432, -1.6563, -1.6077]])\n",
      "tensor([[ 0.1565,  3.0811, -0.7951, -1.7028],\n",
      "        [ 1.1836,  0.0123,  0.2547, -0.1595],\n",
      "        [-0.5265,  1.2856,  0.1052,  0.2470],\n",
      "        [-0.0257,  0.8773, -1.1739, -0.6515]])\n"
     ]
    }
   ],
   "source": [
    "# In place addition\n",
    "print(r2)\n",
    "r2.add_(r)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add multiple matrices together, we get a 3-D tensor. 3-D tensors are used to represent data-like images. Images can be represented as numbers in a matrix, which are stacked together. An example of an image shape is 224, 224, 3, where the first index\n",
    "represents height, the second represents width, and the third represents a channel (RGB). Let's see how a computer sees a panda, using the next code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from scipy import misc\n",
    "\n",
    "face_numpy = misc.face()\n",
    "face_tensor = torch.from_numpy(face_numpy)\n",
    "print(face_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00,  ..., 1.5300e+01, 3.9690e+02,\n",
      "         4.9800e+00],\n",
      "        [2.7310e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9690e+02,\n",
      "         9.1400e+00],\n",
      "        [2.7290e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9283e+02,\n",
      "         4.0300e+00],\n",
      "        ...,\n",
      "        [6.0760e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
      "         5.6400e+00],\n",
      "        [1.0959e-01, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9345e+02,\n",
      "         6.4800e+00],\n",
      "        [4.7410e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
      "         7.8800e+00]], dtype=torch.float64)\n",
      "tensor([ 18.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  12.5000,\n",
      "         12.5000,  12.5000,  12.5000,  12.5000,  12.5000,  12.5000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,  75.0000,  75.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,  21.0000,  21.0000,  21.0000,  21.0000,  75.0000,  90.0000,\n",
      "         85.0000, 100.0000,  25.0000,  25.0000,  25.0000,  25.0000,  25.0000,\n",
      "         25.0000,  17.5000,  80.0000,  80.0000,  12.5000,  12.5000,  12.5000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,  25.0000,  25.0000,  25.0000,  25.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,  28.0000,  28.0000,  28.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  45.0000,  45.0000,\n",
      "         45.0000,  45.0000,  45.0000,  45.0000,  60.0000,  60.0000,  80.0000,\n",
      "         80.0000,  80.0000,  80.0000,  95.0000,  95.0000,  82.5000,  82.5000,\n",
      "         95.0000,  95.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "         30.0000,  30.0000,  30.0000,  30.0000,  30.0000,  30.0000,  22.0000,\n",
      "         22.0000,  22.0000,  22.0000,  22.0000,  22.0000,  22.0000,  22.0000,\n",
      "         22.0000,  22.0000,  80.0000,  80.0000,  90.0000,  20.0000,  20.0000,\n",
      "         20.0000,  20.0000,  20.0000,  20.0000,  20.0000,  20.0000,  20.0000,\n",
      "         20.0000,  20.0000,  20.0000,  20.0000,  20.0000,  20.0000,  20.0000,\n",
      "         20.0000,  40.0000,  40.0000,  40.0000,  40.0000,  40.0000,  20.0000,\n",
      "         20.0000,  20.0000,  20.0000,  90.0000,  90.0000,  55.0000,  80.0000,\n",
      "         52.5000,  52.5000,  52.5000,  80.0000,  80.0000,  80.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,  70.0000,  70.0000,  70.0000,\n",
      "         34.0000,  34.0000,  34.0000,  33.0000,  33.0000,  33.0000,  33.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,  35.0000,  35.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  35.0000,   0.0000,\n",
      "         55.0000,  55.0000,   0.0000,   0.0000,  85.0000,  80.0000,  40.0000,\n",
      "         40.0000,  60.0000,  60.0000,  90.0000,  80.0000,  80.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000], dtype=torch.float64)\n",
      "tensor([[6.3200e-03, 1.8000e+01],\n",
      "        [2.7310e-02, 0.0000e+00],\n",
      "        [2.7290e-02, 0.0000e+00],\n",
      "        ...,\n",
      "        [6.0760e-02, 0.0000e+00],\n",
      "        [1.0959e-01, 0.0000e+00],\n",
      "        [4.7410e-02, 0.0000e+00]], dtype=torch.float64)\n",
      "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
      "         6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
      "         4.9800e+00],\n",
      "        [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 6.4210e+00,\n",
      "         7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9690e+02,\n",
      "         9.1400e+00],\n",
      "        [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 7.1850e+00,\n",
      "         6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9283e+02,\n",
      "         4.0300e+00]], dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64)\n",
      "0.0\n",
      "tensor([2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 7.1850e+00,\n",
      "        6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9283e+02,\n",
      "        4.0300e+00], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(boston_tensor)\n",
    "print(boston_tensor[:,1])\n",
    "print(boston_tensor[:,:2])\n",
    "print(boston_tensor[:3,:])\n",
    "num_ten = boston_tensor[2, 3]\n",
    "print(num_ten)\n",
    "print(num_ten.item())\n",
    "print(boston_tensor[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9397, 0.4973, 0.6941, 0.8952],\n",
      "         [0.0063, 0.3394, 0.5473, 0.4390],\n",
      "         [0.1016, 0.6307, 0.5780, 0.9456]],\n",
      "\n",
      "        [[0.9246, 0.1236, 0.3158, 0.5507],\n",
      "         [0.1612, 0.6510, 0.0571, 0.9151],\n",
      "         [0.2204, 0.2493, 0.5071, 0.7180]]])\n",
      "tensor([[0.9397, 0.4973, 0.6941, 0.8952, 0.0063, 0.3394, 0.5473, 0.4390, 0.1016,\n",
      "         0.6307, 0.5780, 0.9456],\n",
      "        [0.9246, 0.1236, 0.3158, 0.5507, 0.1612, 0.6510, 0.0571, 0.9151, 0.2204,\n",
      "         0.2493, 0.5071, 0.7180]])\n",
      "tensor([[0.9397, 0.4973, 0.6941, 0.8952, 0.0063, 0.3394, 0.5473, 0.4390, 0.1016,\n",
      "         0.6307, 0.5780, 0.9456],\n",
      "        [0.9246, 0.1236, 0.3158, 0.5507, 0.1612, 0.6510, 0.0571, 0.9151, 0.2204,\n",
      "         0.2493, 0.5071, 0.7180]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor with 2 channels, 3 rows and 4 columns (channels, rows, columns)\n",
    "three_dim = torch.rand(2, 3, 4)\n",
    "print(three_dim)\n",
    "# Rechape to 2 rows and 12 columns\n",
    "print(three_dim.view(2, 12))\n",
    "print(three_dim.view(2, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common example for four-dimensional tensor types is a batch of images. Modern CPUs and GPUs are optimized to perform the same operations on multiple examples faster. So, they take a similar time to process one image or a batch of images. So, it is common to use a batch of examples rather than use a single image at a time. Choosing the batch size is not straightforward; it depends on several factors. One major restriction for using a bigger batch or the complete dataset is GPU memory limitations (16, 32, and 64 are commonly used batch sizes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example where we load a batch of cat images of 64 x 224 x 224 x 3 where 64 represents the batch size or the number of images, 244 represents height and width, and 3 represents channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "# Read cat images from disk\n",
    "cats = glob.glob('data/dogscats/train/cats/'+'*.jpg')\n",
    "# Convert images into numpy arrays\n",
    "cat_imgs = np.array([np.array(Image.open(cat).resize((224, 224))) for cat in cats[:64]])\n",
    "cat_imgs = cat_imgs.reshape(-1, 224, 224, 3)\n",
    "cat_tensors = torch.from_numpy(cat_imgs)\n",
    "print(cat_tensors.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common example where you may have to use a five-dimensional tensor is video data. Videos can be split into frames, for example, a 30-second video containing a panda playing with a ball may contain 30 frames, which could be represented as a tensor of shape (1 x 30 x\n",
    "224 x 224 x 3). A batch of such videos can be represented as tensors of shape (32 x 30 x 224 x 224 x 3)- 30 in the example represents, number of frames in that single video clip, where 32 represents the number of such video clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
